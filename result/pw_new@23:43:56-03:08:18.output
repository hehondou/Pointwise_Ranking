Sender: LSF System <openlava@fit07>
Subject: Job 853320: <pw_new> Done

Job <pw_new> was submitted from host <fit-gw> by user <trangnm>.
Job was executed on host(s) <20*fit07>, in queue <gpu>, as user <trangnm>.
</home/trangnm> was used as the home directory.
</home/trangnm/ngannt/cidpython> was used as the working directory.
Started at Fri Aug  3 23:44:00 2018
Results reported at Sat Aug  4 00:42:22 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
PYTHONPATH=/home/trangnm/ngannt/cidpython/ python N_main.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time   :   3076.59 sec.
    Max Memory :      1957 MB
    Max Swap   :     95519 MB

    Max Processes  :         3

The output (if any) follows:

Number of training mentions: 77734
[I] Loading start finished in 0.003 s.
Iter 0 - Loss: 0.9406034350395203 - Acc: 0.5065274238586426
Iter 200 - Loss: 0.6911186027289623 - Acc: 0.5420228354076841
Iter 400 - Loss: 0.6780080946900898 - Acc: 0.5623205832561056
Iter 600 - Loss: 0.6703283505114461 - Acc: 0.575166672666537
Iter 800 - Loss: 0.6645067179396507 - Acc: 0.584862938497248
Iter 1000 - Loss: 0.6591207815574242 - Acc: 0.5928846473519976
Iter 1200 - Loss: 0.6545653606731627 - Acc: 0.5995449475652471
End epochs 1 
Iter 0 - Loss: 0.6266718506813049 - Acc: 0.6229116916656494
Iter 200 - Loss: 0.6161554743401447 - Acc: 0.6459698341972199
Iter 400 - Loss: 0.6144104779807112 - Acc: 0.6476854548192679
Iter 600 - Loss: 0.612251368616266 - Acc: 0.6488248150479575
Iter 800 - Loss: 0.6101381675283263 - Acc: 0.6503490985704867
Iter 1000 - Loss: 0.607918953443026 - Acc: 0.6514099730954661
Iter 1200 - Loss: 0.6058859486663272 - Acc: 0.6527033302309511
End epochs 2 
Iter 0 - Loss: 0.5666750073432922 - Acc: 0.689393937587738
Iter 200 - Loss: 0.5786773265890814 - Acc: 0.6708934348614062
Iter 400 - Loss: 0.5787365790317184 - Acc: 0.6706894970594202
Iter 600 - Loss: 0.5778225677183979 - Acc: 0.6724259646085653
Iter 800 - Loss: 0.5768143672324001 - Acc: 0.6736262548580003
Iter 1000 - Loss: 0.576232951361459 - Acc: 0.6737197978751405
Iter 1200 - Loss: 0.5752050419532687 - Acc: 0.6744478383628058
End epochs 3 
Iter 0 - Loss: 0.5667641758918762 - Acc: 0.6832524538040161
Iter 200 - Loss: 0.5553833898620226 - Acc: 0.6905214234964171
Iter 400 - Loss: 0.554410969081365 - Acc: 0.6913327757557134
Iter 600 - Loss: 0.5528234867208611 - Acc: 0.6928206183351019
Iter 800 - Loss: 0.5521492058418217 - Acc: 0.6942865265144986
Iter 1000 - Loss: 0.5503615578869125 - Acc: 0.6967039289888921
Iter 1200 - Loss: 0.549107497975193 - Acc: 0.6984789028552847
End epochs 4 
Iter 0 - Loss: 0.5190589427947998 - Acc: 0.7383720874786377
Iter 200 - Loss: 0.528516022127066 - Acc: 0.7193909050220281
Iter 400 - Loss: 0.5242428845746856 - Acc: 0.7229260420264151
Iter 600 - Loss: 0.5236736788924244 - Acc: 0.7231869853276778
Iter 800 - Loss: 0.5222414312663298 - Acc: 0.7242081922091795
Iter 1000 - Loss: 0.5216814725846797 - Acc: 0.7249118906634671
Iter 1200 - Loss: 0.5196125000392666 - Acc: 0.7263755110975706
End epochs 5 
Iter 0 - Loss: 0.43925386667251587 - Acc: 0.7857142686843872
Iter 200 - Loss: 0.49712869169107127 - Acc: 0.7436337266395341
Iter 400 - Loss: 0.4979746413795728 - Acc: 0.7421441700987685
Iter 600 - Loss: 0.4981264491347029 - Acc: 0.7417909893735672
Iter 800 - Loss: 0.4975757899876689 - Acc: 0.7419077498040694
Iter 1000 - Loss: 0.49654054793563634 - Acc: 0.7426549289729093
Iter 1200 - Loss: 0.49654242349206956 - Acc: 0.7424869572093942
End epochs 6 
Iter 0 - Loss: 0.468930184841156 - Acc: 0.7577565908432007
Iter 200 - Loss: 0.47929880808835007 - Acc: 0.7544003256517856
Iter 400 - Loss: 0.47919425502085033 - Acc: 0.7546235968049922
Iter 600 - Loss: 0.4782602533127821 - Acc: 0.7560563229284747
Iter 800 - Loss: 0.47696180386787346 - Acc: 0.7580728678221114
Iter 1000 - Loss: 0.47602554185168966 - Acc: 0.7589926314163399
Iter 1200 - Loss: 0.47511119598353735 - Acc: 0.759994369660885
End epochs 7 
Iter 0 - Loss: 0.4819665253162384 - Acc: 0.7649880051612854
Iter 200 - Loss: 0.4497768251753565 - Acc: 0.7772807532282018
Iter 400 - Loss: 0.4501259632390039 - Acc: 0.7783200615956599
Iter 600 - Loss: 0.4518256555381115 - Acc: 0.7775260514506881
Iter 800 - Loss: 0.452591378553381 - Acc: 0.7770097892680269
Iter 1000 - Loss: 0.4533707527490286 - Acc: 0.7767717673942879
Iter 1200 - Loss: 0.4528852103403665 - Acc: 0.7771220421612411
End epochs 8 
Iter 0 - Loss: 0.45798301696777344 - Acc: 0.7742347121238708
Iter 200 - Loss: 0.43608581011568137 - Acc: 0.7889939339006719
Iter 400 - Loss: 0.43765253385998065 - Acc: 0.7879061452171154
Iter 600 - Loss: 0.4389334563010941 - Acc: 0.7865954866623521
Iter 800 - Loss: 0.43856003348449346 - Acc: 0.7869937817255656
Iter 1000 - Loss: 0.4387904609238113 - Acc: 0.7869749327044149
Iter 1200 - Loss: 0.43812782942107276 - Acc: 0.7875543357331389
End epochs 9 
Iter 0 - Loss: 0.38835832476615906 - Acc: 0.8135198354721069
Iter 200 - Loss: 0.4190905215728342 - Acc: 0.7989852105207111
Iter 400 - Loss: 0.4223400552819792 - Acc: 0.7968219364075887
Iter 600 - Loss: 0.4231495020691051 - Acc: 0.796182144203916
Iter 800 - Loss: 0.42444579904147894 - Acc: 0.795350291755762
Iter 1000 - Loss: 0.4254741702046428 - Acc: 0.7949192497161004
Iter 1200 - Loss: 0.4255619210118954 - Acc: 0.794933647289562
End epochs 10 
Iter 0 - Loss: 0.4134046137332916 - Acc: 0.8152454495429993
Iter 200 - Loss: 0.40952352445517015 - Acc: 0.8043498278257266
Iter 400 - Loss: 0.4147035261787976 - Acc: 0.8018230352913055
Iter 600 - Loss: 0.41500358965353246 - Acc: 0.8021429863428315
Iter 800 - Loss: 0.4158694761597113 - Acc: 0.8015342205948895
Iter 1000 - Loss: 0.4162251065363298 - Acc: 0.801291598128034
Iter 1200 - Loss: 0.4167237031916397 - Acc: 0.8011620117663146
End epochs 11 
Iter 0 - Loss: 0.4188152551651001 - Acc: 0.7940446734428406
Iter 200 - Loss: 0.40296931142237646 - Acc: 0.8090769862061116
Iter 400 - Loss: 0.4065606390448877 - Acc: 0.8071804122437265
Iter 600 - Loss: 0.4079674042500989 - Acc: 0.8064151907125844
Iter 800 - Loss: 0.40796784675225484 - Acc: 0.8065792491819974
Iter 1000 - Loss: 0.4082066776690545 - Acc: 0.8063754715643205
Iter 1200 - Loss: 0.4084763563393951 - Acc: 0.806327154991728
End epochs 12 
Iter 0 - Loss: 0.42059633135795593 - Acc: 0.7968036532402039
Iter 200 - Loss: 0.39426804863991427 - Acc: 0.8149927824883911
Iter 400 - Loss: 0.39584949850441514 - Acc: 0.8143208633337234
Iter 600 - Loss: 0.3970687387390264 - Acc: 0.8133573771118126
Iter 800 - Loss: 0.39778845054975315 - Acc: 0.8129934754115663
Iter 1000 - Loss: 0.3989281609996811 - Acc: 0.8120342951554519
Iter 1200 - Loss: 0.40008519293366623 - Acc: 0.8114699140178671
End epochs 13 
Iter 0 - Loss: 0.42659449577331543 - Acc: 0.79347825050354
Iter 200 - Loss: 0.38825313428148106 - Acc: 0.8181159481480347
Iter 400 - Loss: 0.3898710609225561 - Acc: 0.8170571539764689
Iter 600 - Loss: 0.3910787824088841 - Acc: 0.8166037597592778
Iter 800 - Loss: 0.391724797447076 - Acc: 0.8160917006628343
Iter 1000 - Loss: 0.3931412979975328 - Acc: 0.8156532804806392
Iter 1200 - Loss: 0.39396299728247447 - Acc: 0.8151863765259965
End epochs 14 
Iter 0 - Loss: 0.3254703879356384 - Acc: 0.8537634611129761
Iter 200 - Loss: 0.3904574795148859 - Acc: 0.816505791536018
Iter 400 - Loss: 0.3888735307422362 - Acc: 0.8177522093875152
Iter 600 - Loss: 0.3869349706093603 - Acc: 0.8186134738652361
Iter 800 - Loss: 0.3879584333721023 - Acc: 0.8183756789166978
Iter 1000 - Loss: 0.38847859366075854 - Acc: 0.8183715045749843
Iter 1200 - Loss: 0.3897165209675312 - Acc: 0.8177417284940105
End epochs 15 
Iter 0 - Loss: 0.3828534483909607 - Acc: 0.8162729740142822
Iter 200 - Loss: 0.3805163364801834 - Acc: 0.8239721869354817
Iter 400 - Loss: 0.38098640840249764 - Acc: 0.8237215348907242
Iter 600 - Loss: 0.38139214010881306 - Acc: 0.8233842822953984
Iter 800 - Loss: 0.3840187473615606 - Acc: 0.8215171999847993
Iter 1000 - Loss: 0.3841573552830474 - Acc: 0.821498947722333
Iter 1200 - Loss: 0.3841242167872255 - Acc: 0.8213448581052363
End epochs 16 
Iter 0 - Loss: 0.39128097891807556 - Acc: 0.7979002594947815
Iter 200 - Loss: 0.37663741654424526 - Acc: 0.8250797052881611
Iter 400 - Loss: 0.3771515118510943 - Acc: 0.8244147163971404
Iter 600 - Loss: 0.378476190487676 - Acc: 0.8233546142570191
Iter 800 - Loss: 0.3777934805805168 - Acc: 0.823953312880984
Iter 1000 - Loss: 0.37747028708219765 - Acc: 0.8238388429154883
Iter 1200 - Loss: 0.3766049622099763 - Acc: 0.8240779549454174
End epochs 17 
Iter 0 - Loss: 0.3751383125782013 - Acc: 0.8141361474990845
Iter 200 - Loss: 0.36841508938898493 - Acc: 0.8292278196681199
Iter 400 - Loss: 0.36970117591563006 - Acc: 0.8281675156512462
Iter 600 - Loss: 0.3696097287282769 - Acc: 0.8278983583466185
Iter 800 - Loss: 0.3709280640817016 - Acc: 0.8270759121904361
Iter 1000 - Loss: 0.3713725652549412 - Acc: 0.8268395222864904
Iter 1200 - Loss: 0.3712949656278863 - Acc: 0.8266416008923075
End epochs 18 
Iter 0 - Loss: 0.3653284013271332 - Acc: 0.8163506984710693
Iter 200 - Loss: 0.3623418300899107 - Acc: 0.830263244868511
Iter 400 - Loss: 0.36018231273292006 - Acc: 0.8316997441270405
Iter 600 - Loss: 0.3639574990593851 - Acc: 0.8295242003910553
Iter 800 - Loss: 0.3648803210660313 - Acc: 0.8290621871954196
Iter 1000 - Loss: 0.36417951087256173 - Acc: 0.8292994303898616
Iter 1200 - Loss: 0.3651441098450622 - Acc: 0.8285249374887529
End epochs 19 
Iter 0 - Loss: 0.36637231707572937 - Acc: 0.8229665160179138
Iter 200 - Loss: 0.3595762917058385 - Acc: 0.8295337456968886
Iter 400 - Loss: 0.3579179252918224 - Acc: 0.8317180556846676
Iter 600 - Loss: 0.35948378571654716 - Acc: 0.8314965947495523
Iter 800 - Loss: 0.36049480455347366 - Acc: 0.8308500940731254
Iter 1000 - Loss: 0.36115977188923976 - Acc: 0.8305600891103754
Iter 1200 - Loss: 0.3610043134369719 - Acc: 0.8306907848652753
End epochs 20 
Iter 0 - Loss: 0.3379623591899872 - Acc: 0.8387500047683716
Iter 200 - Loss: 0.3493604059539624 - Acc: 0.8371987680890667
Iter 400 - Loss: 0.3493425613478235 - Acc: 0.836445053022104
Iter 600 - Loss: 0.3513403959361567 - Acc: 0.8349185727797015
Iter 800 - Loss: 0.35345736291078145 - Acc: 0.8337584280789122
Iter 1000 - Loss: 0.3545233022857022 - Acc: 0.8332032804841643
Iter 1200 - Loss: 0.3561108805902991 - Acc: 0.8324519234037121
End epochs 21 
Iter 0 - Loss: 0.3317827582359314 - Acc: 0.8661137223243713
Iter 200 - Loss: 0.347541126297481 - Acc: 0.837124464523733
Iter 400 - Loss: 0.35033749025361494 - Acc: 0.8360845529825015
Iter 600 - Loss: 0.35064011544435475 - Acc: 0.8360782465006468
Iter 800 - Loss: 0.3516440547807386 - Acc: 0.8354440763797355
Iter 1000 - Loss: 0.3523991419956996 - Acc: 0.8348030120461851
Iter 1200 - Loss: 0.352461137243552 - Acc: 0.8347658816225622
End epochs 22 
Iter 0 - Loss: 0.3900825083255768 - Acc: 0.7951482534408569
Iter 200 - Loss: 0.34761581106565487 - Acc: 0.8367054106584236
Iter 400 - Loss: 0.3474099326163456 - Acc: 0.8369078587118229
Iter 600 - Loss: 0.34649807403170924 - Acc: 0.8372333721194212
Iter 800 - Loss: 0.3482387559616313 - Acc: 0.8364671041605327
Iter 1000 - Loss: 0.34897523665880703 - Acc: 0.8362624413602716
Iter 1200 - Loss: 0.34958381118325765 - Acc: 0.8360389674533714
End epochs 23 
Iter 0 - Loss: 0.3470071256160736 - Acc: 0.8356643319129944
Iter 200 - Loss: 0.3387063910712057 - Acc: 0.8414182443523881
Iter 400 - Loss: 0.34326698751818213 - Acc: 0.8392107797382479
Iter 600 - Loss: 0.344229757835385 - Acc: 0.8385604299642083
Iter 800 - Loss: 0.34472965368170866 - Acc: 0.8382148555899679
Iter 1000 - Loss: 0.3455462158321739 - Acc: 0.837775746604184
Iter 1200 - Loss: 0.3461617130621784 - Acc: 0.837420123304356
End epochs 24 
Iter 0 - Loss: 0.35278990864753723 - Acc: 0.8445190191268921
Iter 200 - Loss: 0.33764607173886463 - Acc: 0.8417375425794231
Iter 400 - Loss: 0.33717009700147293 - Acc: 0.8419901550262051
Iter 600 - Loss: 0.34074434985138613 - Acc: 0.8405984582599506
Iter 800 - Loss: 0.3416122549333227 - Acc: 0.8398093391447031
Iter 1000 - Loss: 0.34249012804888823 - Acc: 0.8394134501358131
Iter 1200 - Loss: 0.3436683816625911 - Acc: 0.8390350855955176
End epochs 25 
Iter 0 - Loss: 0.3299195170402527 - Acc: 0.851089596748352
Iter 200 - Loss: 0.3400194714615001 - Acc: 0.8409611920812237
Iter 400 - Loss: 0.3395372796385663 - Acc: 0.8403998249189515
Iter 600 - Loss: 0.33876401761208913 - Acc: 0.840909398831861
Iter 800 - Loss: 0.3397099474321739 - Acc: 0.8404675748910797
Iter 1000 - Loss: 0.340554423652567 - Acc: 0.8402150163164624
Iter 1200 - Loss: 0.34072093307029 - Acc: 0.8404135708010861
End epochs 26 
Iter 0 - Loss: 0.37181320786476135 - Acc: 0.8253588676452637
Iter 200 - Loss: 0.32949676991102117 - Acc: 0.8453264633814493
Iter 400 - Loss: 0.3350192092897886 - Acc: 0.8426779499672298
Iter 600 - Loss: 0.336274085445531 - Acc: 0.8421909300340789
Iter 800 - Loss: 0.33791795499464694 - Acc: 0.8412572926796331
Iter 1000 - Loss: 0.3391984887235053 - Acc: 0.8408306404189034
Iter 1200 - Loss: 0.33892938804864686 - Acc: 0.841423093031884
End epochs 27 
Iter 0 - Loss: 0.31635212898254395 - Acc: 0.8614718317985535
Iter 200 - Loss: 0.33492010387022103 - Acc: 0.8434428928503349
Iter 400 - Loss: 0.3351199510240198 - Acc: 0.8435622220324757
Iter 600 - Loss: 0.3353805965968654 - Acc: 0.8434655255763582
Iter 800 - Loss: 0.33703210068106204 - Acc: 0.8425842442464888
Iter 1000 - Loss: 0.33666642840866084 - Acc: 0.8427078161206278
Iter 1200 - Loss: 0.3370433108420495 - Acc: 0.8426279862357814
End epochs 28 
Iter 0 - Loss: 0.3620149493217468 - Acc: 0.8233765959739685
Iter 200 - Loss: 0.32971732829933736 - Acc: 0.8469732107214667
Iter 400 - Loss: 0.3305670619754125 - Acc: 0.8462297106324289
Iter 600 - Loss: 0.3315988470631312 - Acc: 0.8454730984771907
Iter 800 - Loss: 0.33165201448025033 - Acc: 0.8453661265891143
Iter 1000 - Loss: 0.33202283979057673 - Acc: 0.8450710835990373
Iter 1200 - Loss: 0.333296471516556 - Acc: 0.8446346873744739
End epochs 29 
Iter 0 - Loss: 0.276607871055603 - Acc: 0.8642857074737549
Iter 200 - Loss: 0.3298437160935568 - Acc: 0.8445987197297129
Iter 400 - Loss: 0.3313086857819498 - Acc: 0.844721969523632
Iter 600 - Loss: 0.3326370908991866 - Acc: 0.8439789566144769
Iter 800 - Loss: 0.3328436219997323 - Acc: 0.8443704313702054
Iter 1000 - Loss: 0.3327868705118572 - Acc: 0.8444808532188941
Iter 1200 - Loss: 0.33305443334490137 - Acc: 0.8442905178475042
End epochs 30 
Saved the model
[I] Start training finished in 3493.281 s.


PS:

Read file </home/trangnm/ngannt/cidpython//development/Pointwise/result/pw_new@23:43:56-03:08:18.error> for stderr output of this job.

