Sender: LSF System <openlava@fit07>
Subject: Job 853324: <pw_new> Done

Job <pw_new> was submitted from host <fit-gw> by user <trangnm>.
Job was executed on host(s) <20*fit07>, in queue <gpu>, as user <trangnm>.
</home/trangnm> was used as the home directory.
</home/trangnm/ngannt/cidpython> was used as the working directory.
Started at Sat Aug  4 07:31:33 2018
Results reported at Sat Aug  4 08:30:19 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
PYTHONPATH=/home/trangnm/ngannt/cidpython/ python N_main.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time   :   3100.58 sec.
    Max Memory :      1957 MB
    Max Swap   :     95519 MB

    Max Processes  :         3

The output (if any) follows:

Number of training mentions: 77734
[I] Loading start finished in 0.002 s.
Iter 0 - Loss: 2.600311756134033 - Acc: 0.5
Iter 200 - Loss: 0.7997915314797738 - Acc: 0.5124224547426499
Iter 400 - Loss: 0.7501295975913431 - Acc: 0.5298378359795806
Iter 600 - Loss: 0.7266059098346856 - Acc: 0.545191621274599
Iter 800 - Loss: 0.7112222318345688 - Acc: 0.5581681836633646
Iter 1000 - Loss: 0.6993267874379496 - Acc: 0.5700946355854476
Iter 1200 - Loss: 0.6903466148539249 - Acc: 0.5796898470184983
End epochs 1 
Iter 0 - Loss: 0.6503481864929199 - Acc: 0.6097851991653442
Iter 200 - Loss: 0.633735660000227 - Acc: 0.6445572242807986
Iter 400 - Loss: 0.6308852165119904 - Acc: 0.6472539959703003
Iter 600 - Loss: 0.6292726105937545 - Acc: 0.6492180094346032
Iter 800 - Loss: 0.6273454877916496 - Acc: 0.6510572673080863
Iter 1000 - Loss: 0.6253750704147003 - Acc: 0.6527437304521536
Iter 1200 - Loss: 0.6231931300087833 - Acc: 0.6549965837515959
End epochs 2 
Iter 0 - Loss: 0.5983527302742004 - Acc: 0.6792929172515869
Iter 200 - Loss: 0.5978782698882753 - Acc: 0.6778426469855048
Iter 400 - Loss: 0.5978284910729996 - Acc: 0.6784236823531458
Iter 600 - Loss: 0.5967359546813711 - Acc: 0.6798550786075497
Iter 800 - Loss: 0.5959300673409794 - Acc: 0.6804753880524606
Iter 1000 - Loss: 0.5955513775289119 - Acc: 0.68045325010092
Iter 1200 - Loss: 0.594168779802362 - Acc: 0.6817454196928343
End epochs 3 
Iter 0 - Loss: 0.5556627511978149 - Acc: 0.7220873832702637
Iter 200 - Loss: 0.5754226644833883 - Acc: 0.6977149301500463
Iter 400 - Loss: 0.5750955579584079 - Acc: 0.6977919246490459
Iter 600 - Loss: 0.5748038772933693 - Acc: 0.6977088675522765
Iter 800 - Loss: 0.574962432576476 - Acc: 0.6977877657809358
Iter 1000 - Loss: 0.5739516191906505 - Acc: 0.6987167803438512
Iter 1200 - Loss: 0.574412160967907 - Acc: 0.6984223654427
End epochs 4 
Iter 0 - Loss: 0.5334264039993286 - Acc: 0.7441860437393188
Iter 200 - Loss: 0.5648815958061029 - Acc: 0.7066162412439413
Iter 400 - Loss: 0.5620061487628337 - Acc: 0.7088595159035965
Iter 600 - Loss: 0.5616989844849026 - Acc: 0.70906294483115
Iter 800 - Loss: 0.5613011966707108 - Acc: 0.7092284737305993
Iter 1000 - Loss: 0.5606657819195346 - Acc: 0.7096595388430578
Iter 1200 - Loss: 0.5597291662730742 - Acc: 0.710428395636572
End epochs 5 
Iter 0 - Loss: 0.5030158758163452 - Acc: 0.7573696374893188
Iter 200 - Loss: 0.5484852850140624 - Acc: 0.7199373494333295
Iter 400 - Loss: 0.5487618175825276 - Acc: 0.7190053020034942
Iter 600 - Loss: 0.5491701182033774 - Acc: 0.7182858745984348
Iter 800 - Loss: 0.5490621448158474 - Acc: 0.7182856006419912
Iter 1000 - Loss: 0.5489957951880121 - Acc: 0.7183285149541887
Iter 1200 - Loss: 0.549133069856677 - Acc: 0.718270462964794
End epochs 6 
Iter 0 - Loss: 0.5559768080711365 - Acc: 0.6968973875045776
Iter 200 - Loss: 0.5393309271454219 - Acc: 0.7260328406718239
Iter 400 - Loss: 0.5409071937463528 - Acc: 0.7251097197247265
Iter 600 - Loss: 0.541412289943949 - Acc: 0.7245389902452859
Iter 800 - Loss: 0.541161414984609 - Acc: 0.7247224642096387
Iter 1000 - Loss: 0.5408639939693543 - Acc: 0.7245425611109166
Iter 1200 - Loss: 0.5393584029412488 - Acc: 0.7249684944736471
End epochs 7 
Iter 0 - Loss: 0.545377790927887 - Acc: 0.7182254195213318
Iter 200 - Loss: 0.519461466008751 - Acc: 0.731863922444149
Iter 400 - Loss: 0.5189298140140542 - Acc: 0.7329124479817036
Iter 600 - Loss: 0.5201014943309314 - Acc: 0.7316213222390998
Iter 800 - Loss: 0.5203556719418619 - Acc: 0.7309772358107358
Iter 1000 - Loss: 0.5203676905843999 - Acc: 0.7309107212396292
Iter 1200 - Loss: 0.5199031790626932 - Acc: 0.7311342501024918
End epochs 8 
Iter 0 - Loss: 0.5317137241363525 - Acc: 0.7270408272743225
Iter 200 - Loss: 0.5087122854901783 - Acc: 0.7364613416776136
Iter 400 - Loss: 0.5102381374770566 - Acc: 0.7352281215779501
Iter 600 - Loss: 0.5106690531959153 - Acc: 0.7348976494270236
Iter 800 - Loss: 0.5103141739127341 - Acc: 0.7352700688865748
Iter 1000 - Loss: 0.5098584781695794 - Acc: 0.735331394098379
Iter 1200 - Loss: 0.5087210598039588 - Acc: 0.7357958831656088
End epochs 9 
Iter 0 - Loss: 0.4916669428348541 - Acc: 0.7365967631340027
Iter 200 - Loss: 0.49339155356089276 - Acc: 0.7427544223135384
Iter 400 - Loss: 0.4955955394485645 - Acc: 0.740884030846289
Iter 600 - Loss: 0.49568687838048187 - Acc: 0.7408911905153818
Iter 800 - Loss: 0.4951872971843691 - Acc: 0.7413387282213171
Iter 1000 - Loss: 0.4959132346835408 - Acc: 0.7407891593732081
Iter 1200 - Loss: 0.4957352207661866 - Acc: 0.7407401063162322
End epochs 10 
Iter 0 - Loss: 0.46860381960868835 - Acc: 0.7713178396224976
Iter 200 - Loss: 0.47972371002927944 - Acc: 0.7490888611594243
Iter 400 - Loss: 0.4853823985393505 - Acc: 0.7452092594339366
Iter 600 - Loss: 0.48659218716343705 - Acc: 0.7447564900417296
Iter 800 - Loss: 0.48740094170885884 - Acc: 0.7441249704837204
Iter 1000 - Loss: 0.48751611571450093 - Acc: 0.7441557124778108
Iter 1200 - Loss: 0.48669337471954827 - Acc: 0.7455710554797882
End epochs 11 
Iter 0 - Loss: 0.4325709939002991 - Acc: 0.792803943157196
Iter 200 - Loss: 0.4622928301493327 - Acc: 0.7694138460491428
Iter 400 - Loss: 0.463158006457022 - Acc: 0.7698245241754965
Iter 600 - Loss: 0.46315464843529436 - Acc: 0.7698843489074072
Iter 800 - Loss: 0.4629852029119389 - Acc: 0.770770316266835
Iter 1000 - Loss: 0.46303703922491807 - Acc: 0.7709876112528257
Iter 1200 - Loss: 0.46266928935527407 - Acc: 0.7715096248377372
End epochs 12 
Iter 0 - Loss: 0.44991442561149597 - Acc: 0.7773972749710083
Iter 200 - Loss: 0.44574229233893586 - Acc: 0.7828383582148386
Iter 400 - Loss: 0.4465208901580135 - Acc: 0.7825928688643876
Iter 600 - Loss: 0.44819701382403765 - Acc: 0.7813067381671582
Iter 800 - Loss: 0.4487022091535742 - Acc: 0.7813933261771328
Iter 1000 - Loss: 0.4495489973943312 - Acc: 0.7808768719464511
Iter 1200 - Loss: 0.4500389666382617 - Acc: 0.7806423253858219
End epochs 13 
Iter 0 - Loss: 0.4649307429790497 - Acc: 0.770531415939331
Iter 200 - Loss: 0.43806170927944466 - Acc: 0.7885421541199755
Iter 400 - Loss: 0.4406210948106951 - Acc: 0.7865258202588469
Iter 600 - Loss: 0.4417050265135265 - Acc: 0.7855641870649405
Iter 800 - Loss: 0.44162563672672944 - Acc: 0.7853896907355157
Iter 1000 - Loss: 0.4423343239130674 - Acc: 0.7851939820028566
Iter 1200 - Loss: 0.4427249335577645 - Acc: 0.784946788409469
End epochs 14 
Iter 0 - Loss: 0.36790814995765686 - Acc: 0.8376343846321106
Iter 200 - Loss: 0.436167013585864 - Acc: 0.7891343167765223
Iter 400 - Loss: 0.43542056131244006 - Acc: 0.7897383133669447
Iter 600 - Loss: 0.4340977766450352 - Acc: 0.7902026443235489
Iter 800 - Loss: 0.43467726403110185 - Acc: 0.7898402072665992
Iter 1000 - Loss: 0.4355211586325795 - Acc: 0.7895091477926676
Iter 1200 - Loss: 0.4359850649234159 - Acc: 0.7893691704632539
End epochs 15 
Iter 0 - Loss: 0.42945340275764465 - Acc: 0.787401556968689
Iter 200 - Loss: 0.4270876078166772 - Acc: 0.7951794637376396
Iter 400 - Loss: 0.4274120274327342 - Acc: 0.7952645272388126
Iter 600 - Loss: 0.4293985174420273 - Acc: 0.7937024468788489
Iter 800 - Loss: 0.4308359296283174 - Acc: 0.792379642842563
Iter 1000 - Loss: 0.43105321574758937 - Acc: 0.7922426986170339
Iter 1200 - Loss: 0.4313190220347253 - Acc: 0.7920352471162636
End epochs 16 
Iter 0 - Loss: 0.428690642118454 - Acc: 0.7769029140472412
Iter 200 - Loss: 0.4211996007914567 - Acc: 0.7968436888794401
Iter 400 - Loss: 0.42195319661178493 - Acc: 0.7969840653519381
Iter 600 - Loss: 0.4221221429238502 - Acc: 0.7969561220207151
Iter 800 - Loss: 0.4221069748779659 - Acc: 0.7971513905328758
Iter 1000 - Loss: 0.4223296020652626 - Acc: 0.7972312901879881
Iter 1200 - Loss: 0.4221547628372138 - Acc: 0.7974579616152774
End epochs 17 
Iter 0 - Loss: 0.39087316393852234 - Acc: 0.8075916171073914
Iter 200 - Loss: 0.4099393842825249 - Acc: 0.8055644159886375
Iter 400 - Loss: 0.41291034704729207 - Acc: 0.8035600574831119
Iter 600 - Loss: 0.4132908725004625 - Acc: 0.8031250832481511
Iter 800 - Loss: 0.4154024947523029 - Acc: 0.8018011722374201
Iter 1000 - Loss: 0.4155940207746717 - Acc: 0.801757819109506
Iter 1200 - Loss: 0.4156447849752107 - Acc: 0.8019476341863755
End epochs 18 
Iter 0 - Loss: 0.4518412947654724 - Acc: 0.7665876746177673
Iter 200 - Loss: 0.405128098838958 - Acc: 0.8071759838369948
Iter 400 - Loss: 0.4055582756859406 - Acc: 0.8066994772290351
Iter 600 - Loss: 0.4081454738701838 - Acc: 0.8058546008960578
Iter 800 - Loss: 0.4085088266564368 - Acc: 0.8063953925905454
Iter 1000 - Loss: 0.40704648091004686 - Acc: 0.8081879892668405
Iter 1200 - Loss: 0.40669753234352696 - Acc: 0.8091389152727755
End epochs 19 
Iter 0 - Loss: 0.41744565963745117 - Acc: 0.8038277626037598
Iter 200 - Loss: 0.3914886640375526 - Acc: 0.821210956395562
Iter 400 - Loss: 0.391827342590489 - Acc: 0.8213174118662713
Iter 600 - Loss: 0.3919540118060374 - Acc: 0.8218468259059252
Iter 800 - Loss: 0.39210173688577804 - Acc: 0.8220614850446675
Iter 1000 - Loss: 0.39222823552318387 - Acc: 0.8222732767239437
Iter 1200 - Loss: 0.3917542880619694 - Acc: 0.8225468861669625
End epochs 20 
Iter 0 - Loss: 0.36640313267707825 - Acc: 0.824999988079071
Iter 200 - Loss: 0.3772766689459483 - Acc: 0.8303881759074196
Iter 400 - Loss: 0.3785305592484605 - Acc: 0.8303681867675591
Iter 600 - Loss: 0.38115219184245525 - Acc: 0.8289285056206231
Iter 800 - Loss: 0.3834066059854295 - Acc: 0.827931081162261
Iter 1000 - Loss: 0.3837291516743221 - Acc: 0.8276505870418949
Iter 1200 - Loss: 0.3847350761058626 - Acc: 0.82711380208958
End epochs 21 
Iter 0 - Loss: 0.36946630477905273 - Acc: 0.8436018824577332
Iter 200 - Loss: 0.3736090124839574 - Acc: 0.8335988405925124
Iter 400 - Loss: 0.3748259898878987 - Acc: 0.8329936356615841
Iter 600 - Loss: 0.37576492594403155 - Acc: 0.8327379261396094
Iter 800 - Loss: 0.37726661618729207 - Acc: 0.8320460068003813
Iter 1000 - Loss: 0.3779054859301427 - Acc: 0.8316865741432488
Iter 1200 - Loss: 0.37818601050047357 - Acc: 0.8315383765620058
End epochs 22 
Iter 0 - Loss: 0.4068555235862732 - Acc: 0.8072776198387146
Iter 200 - Loss: 0.37071598080260243 - Acc: 0.8363365225530975
Iter 400 - Loss: 0.37059875780210233 - Acc: 0.836324242285065
Iter 600 - Loss: 0.3698819419508568 - Acc: 0.8365503785614166
Iter 800 - Loss: 0.3717108349154207 - Acc: 0.8353925589913881
Iter 1000 - Loss: 0.37253900332288903 - Acc: 0.8349790307548972
Iter 1200 - Loss: 0.3729669957434903 - Acc: 0.8346696667726788
End epochs 23 
Iter 0 - Loss: 0.32414039969444275 - Acc: 0.8601398468017578
Iter 200 - Loss: 0.36309210281466964 - Acc: 0.8403471613404763
Iter 400 - Loss: 0.3656906117673527 - Acc: 0.8389553423237027
Iter 600 - Loss: 0.3669296312153637 - Acc: 0.8383730182830188
Iter 800 - Loss: 0.36800643831454266 - Acc: 0.8377960831782643
Iter 1000 - Loss: 0.3691034774918418 - Acc: 0.8371742331421935
Iter 1200 - Loss: 0.36921056859399953 - Acc: 0.8370514158702314
End epochs 24 
Iter 0 - Loss: 0.3903363049030304 - Acc: 0.8333333134651184
Iter 200 - Loss: 0.35778165886651225 - Acc: 0.8438516152438833
Iter 400 - Loss: 0.35963247905942863 - Acc: 0.8431609087156833
Iter 600 - Loss: 0.3610392585272797 - Acc: 0.8423175056048122
Iter 800 - Loss: 0.3625864948003033 - Acc: 0.8413560583945666
Iter 1000 - Loss: 0.362891125899333 - Acc: 0.8408814934821991
Iter 1200 - Loss: 0.3637666236748803 - Acc: 0.8405288541247505
End epochs 25 
Iter 0 - Loss: 0.35154813528060913 - Acc: 0.8644067645072937
Iter 200 - Loss: 0.36128790298504615 - Acc: 0.8421632558552187
Iter 400 - Loss: 0.359815089779899 - Acc: 0.8424240374505668
Iter 600 - Loss: 0.3580193357439882 - Acc: 0.8437438140097949
Iter 800 - Loss: 0.35934750815753486 - Acc: 0.8431443892763497
Iter 1000 - Loss: 0.3605782707909366 - Acc: 0.8425108813620233
Iter 1200 - Loss: 0.36048789033286277 - Acc: 0.8424092095956318
End epochs 26 
Iter 0 - Loss: 0.38278430700302124 - Acc: 0.8540669679641724
Iter 200 - Loss: 0.34827193810572077 - Acc: 0.847820542048459
Iter 400 - Loss: 0.3532249441467913 - Acc: 0.8453858595833814
Iter 600 - Loss: 0.3546423136493727 - Acc: 0.8448626229449635
Iter 800 - Loss: 0.35630247863788583 - Acc: 0.8438708374413956
Iter 1000 - Loss: 0.35729823716275105 - Acc: 0.8435473652867289
Iter 1200 - Loss: 0.3567923485835724 - Acc: 0.8440946268598603
End epochs 27 
Iter 0 - Loss: 0.3263866603374481 - Acc: 0.8777056336402893
Iter 200 - Loss: 0.35250445429365435 - Acc: 0.8465607611101065
Iter 400 - Loss: 0.35175548423258146 - Acc: 0.8466950173389882
Iter 600 - Loss: 0.35188264135711406 - Acc: 0.8467918063162171
Iter 800 - Loss: 0.3528220422110159 - Acc: 0.8461410360836358
Iter 1000 - Loss: 0.35315380244702843 - Acc: 0.8459651614283468
Iter 1200 - Loss: 0.3536272919446007 - Acc: 0.8456791623446666
End epochs 28 
Iter 0 - Loss: 0.3544750213623047 - Acc: 0.8441558480262756
Iter 200 - Loss: 0.3454892771754099 - Acc: 0.8506043416943716
Iter 400 - Loss: 0.347926826919998 - Acc: 0.8489118970540396
Iter 600 - Loss: 0.3487037195639682 - Acc: 0.8481742538350593
Iter 800 - Loss: 0.3485004711761308 - Acc: 0.8483842837527747
Iter 1000 - Loss: 0.34889230474487287 - Acc: 0.8484432107799655
Iter 1200 - Loss: 0.3501510358075119 - Acc: 0.8477392396164576
End epochs 29 
Iter 0 - Loss: 0.28792741894721985 - Acc: 0.8761904835700989
Iter 200 - Loss: 0.34392158145928264 - Acc: 0.8522906217409011
Iter 400 - Loss: 0.3443632982764161 - Acc: 0.8515745640692866
Iter 600 - Loss: 0.3454166881851666 - Acc: 0.8505989050309789
Iter 800 - Loss: 0.34609063998441425 - Acc: 0.8500317595573549
Iter 1000 - Loss: 0.3460724275488477 - Acc: 0.8502994833530841
Iter 1200 - Loss: 0.3464992390782708 - Acc: 0.8503020149186489
End epochs 30 
Saved the model
[I] Start training finished in 3514.103 s.


PS:

Read file </home/trangnm/ngannt/cidpython//development/Pointwise/result/pw_new@07:31:30-04:08:18.error> for stderr output of this job.

